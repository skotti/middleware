{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "\n",
    "logs_per_experiment = 36\n",
    "\n",
    "value_sizes = [64, 256, 512, 1024]\n",
    "client_numbers = [4, 8, 16, 32]\n",
    "workers = [8, 32, 64]\n",
    "repetitions = 3\n",
    "memtier_instances = 3\n",
    "nServers = 3\n",
    "experiments = len(workers) * len(value_sizes) * len(client_numbers) * repetitions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create middleware 1 logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw=1\n",
    "path_to_experiment=path_to_experiment=\"/home/anastasiia/final_ex/final_copy/\"\n",
    "path_to_logs = \"/home/anastasiia/final_ex/final_copy/middleware1_logs/\"\n",
    "\n",
    "mw_log = open(path_to_experiment+\"mw_\"+str(mw)+\".log\",\"r\")\n",
    "lines = mw_log.readlines()\n",
    "\n",
    "def is_zero(line):\n",
    "    parts = line.split(\" \")\n",
    "    if (parts[1] == '0' and parts[2] == '0' and parts[3] == '0' and parts[4] == '0' and parts[5] == '0' and\n",
    "        parts[6] == '0' and parts[7] == '0' and parts[8] == '0' and parts[9] == '0' and parts[10] == '0'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_following_lines(i):\n",
    "    all_zero = True\n",
    "    \n",
    "    n = 0\n",
    "    for j in range(64):\n",
    "        n = j\n",
    "        parts = lines[i+j].split(\" \")\n",
    "        if parts[0] == str(j) and is_zero(lines[i+j]):\n",
    "            continue\n",
    "        elif (j == 8 or j == 32) and lines[i + j] != \"DEBUG ethz.Middleware: CLIENT DISCONNECTED\":\n",
    "            break\n",
    "        else:\n",
    "            all_zero = False\n",
    "            break\n",
    "        \n",
    "    return all_zero, n\n",
    "\n",
    "new_experiment_positions=[]\n",
    "new_experiment_positions_end=[]\n",
    "invalidated_experiments=[]\n",
    "\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    parts = lines[i].split(\" \")\n",
    "    if is_zero(lines[i]) or lines[i].startswith(\"DEBUG ethz.StatPrinter\") or lines[i].startswith(\"SIGTERM call\") or lines[i].startswith(\"DEBUG ethz.Middleware: CLIENT DISCONNECTED\") :\n",
    "        i += 1\n",
    "        continue\n",
    "    new_experiment_positions.append(i)\n",
    "    while True:\n",
    "        if not is_zero(lines[i]):\n",
    "            i += 1\n",
    "        elif is_zero(lines[i]):\n",
    "            condition, nlines = check_following_lines(i)\n",
    "            if (condition):\n",
    "                break\n",
    "            else:\n",
    "                print(\"line numer=\"+str(i))\n",
    "                print(\"condition not ok\")\n",
    "                i+=1\n",
    "                continue\n",
    "    new_experiment_positions_end.append(i)\n",
    "\n",
    "for i in range(len(new_experiment_positions)):\n",
    "    for j in range(new_experiment_positions[i], new_experiment_positions_end[i]):\n",
    "        if lines[j].startswith(\"ERROR\"):\n",
    "            print(\"Error in line=\"+str(j))\n",
    "            print(\"Invalidate experiment=\"+str(i))\n",
    "            invalidated_experiments.append(i)\n",
    "        elif lines[j].startswith(\"SIGTERM\"):\n",
    "            print(\"Sigterm reported in \"+ str(i)+\".Check the data\")\n",
    "            \n",
    "for i in range(len(new_experiment_positions)):\n",
    "    if i not in invalidated_experiments:\n",
    "        f = open(path_to_logs+\"log_\"+str(i)+\".log\", \"w\")\n",
    "        for j in range(new_experiment_positions[i], new_experiment_positions_end[i]):\n",
    "            if (lines[j][0].isdigit()):\n",
    "                f.write(lines[j])\n",
    "        f.close()\n",
    "#print(new_experiment_positions)\n",
    "#print(\"\\n\")\n",
    "#print(new_experiment_positions_end)\n",
    "#print([[a, b] for a, b in zip(new_experiment_positions, new_experiment_positions_end)])\n",
    "j = 0\n",
    "for i in new_experiment_positions:\n",
    "    print(j)\n",
    "    print(i)\n",
    "    print(lines[i])\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create middleware 2 logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw=2\n",
    "path_to_experiment=path_to_experiment=\"/home/anastasiia/final_ex/final_copy/\"\n",
    "path_to_logs = \"/home/anastasiia/final_ex/final_copy/middleware2_logs/\"\n",
    "\n",
    "mw_log = open(path_to_experiment+\"mw_\"+str(mw)+\".log\",\"r\")\n",
    "lines = mw_log.readlines()\n",
    "\n",
    "def is_zero(line):\n",
    "    parts = line.split(\" \")\n",
    "    if (parts[1] == '0' and parts[2] == '0' and parts[3] == '0' and parts[4] == '0' and parts[5] == '0' and\n",
    "        parts[6] == '0' and parts[7] == '0' and parts[8] == '0' and parts[9] == '0' and parts[10] == '0'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_following_lines(i):\n",
    "    all_zero = True\n",
    "    \n",
    "    n = 0\n",
    "    for j in range(64):\n",
    "        n = j\n",
    "        parts = lines[i+j].split(\" \")\n",
    "        if parts[0] == str(j) and is_zero(lines[i+j]):\n",
    "            continue\n",
    "        elif j == 8 or j == 32:\n",
    "            break\n",
    "        else:\n",
    "            all_zero = False\n",
    "            break\n",
    "        \n",
    "    return all_zero, n\n",
    "\n",
    "new_experiment_positions=[]\n",
    "new_experiment_positions_end=[]\n",
    "invalidated_experiments=[]\n",
    "\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    parts = lines[i].split(\" \")\n",
    "    if is_zero(lines[i]) or lines[i].startswith(\"DEBUG ethz.StatPrinter\") or lines[i].startswith(\"SIGTERM call\") or lines[i].startswith(\"DEBUG ethz.Middleware: CLIENT DISCONNECTED\"):\n",
    "        i += 1\n",
    "        continue\n",
    "    new_experiment_positions.append(i)\n",
    "    while True:\n",
    "        if not is_zero(lines[i]):\n",
    "            i += 1\n",
    "        elif is_zero(lines[i]):\n",
    "            condition, nlines = check_following_lines(i)\n",
    "            if (condition):\n",
    "                break\n",
    "            else:\n",
    "                print(\"line numer=\"+str(i))\n",
    "                print(\"condition not ok\")\n",
    "                i+=1\n",
    "                continue\n",
    "    new_experiment_positions_end.append(i)\n",
    "\n",
    "for i in range(len(new_experiment_positions)):\n",
    "    for j in range(new_experiment_positions[i], new_experiment_positions_end[i]):\n",
    "        if lines[j].startswith(\"ERROR\"):\n",
    "            print(\"Error in line=\"+str(j))\n",
    "            print(\"Invalidate experiment=\"+str(i))\n",
    "            invalidated_experiments.append(i)\n",
    "        elif lines[j].startswith(\"SIGTERM\"):\n",
    "            print(\"Sigterm reported in \"+ str(i)+\".Check the data\")\n",
    "            \n",
    "for i in range(len(new_experiment_positions)):\n",
    "    if i not in invalidated_experiments:\n",
    "        f = open(path_to_logs+\"log_\"+str(i)+\".log\", \"w\")\n",
    "        for j in range(new_experiment_positions[i], new_experiment_positions_end[i]):\n",
    "            if (lines[j][0].isdigit()):\n",
    "                f.write(lines[j])\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=108\n",
      "k=252\n",
      "k=396\n",
      "k=540\n",
      "Start adding data to global table\n",
      "m=0\n",
      "m=1\n",
      "m=2\n",
      "m=3\n",
      "m=4\n",
      "m=5\n",
      "m=6\n",
      "m=7\n",
      "m=8\n",
      "m=9\n",
      "m=10\n",
      "m=11\n",
      "m=12\n",
      "m=13\n",
      "m=14\n",
      "m=15\n",
      "m=16\n",
      "m=17\n",
      "m=18\n",
      "m=19\n",
      "m=20\n",
      "m=21\n",
      "m=22\n",
      "m=23\n",
      "m=24\n",
      "m=25\n",
      "m=26\n",
      "m=27\n",
      "m=28\n",
      "m=29\n",
      "m=30\n",
      "m=31\n",
      "m=32\n",
      "m=33\n",
      "m=34\n",
      "m=35\n",
      "m=36\n",
      "m=37\n",
      "m=38\n",
      "m=39\n",
      "m=40\n",
      "m=41\n",
      "m=42\n",
      "m=43\n",
      "m=44\n",
      "m=45\n",
      "m=46\n",
      "m=47\n",
      "m=48\n",
      "m=49\n",
      "m=50\n",
      "m=51\n",
      "m=52\n",
      "m=53\n",
      "m=54\n",
      "m=55\n",
      "m=56\n",
      "m=57\n",
      "m=58\n",
      "m=59\n",
      "m=60\n",
      "m=61\n",
      "m=62\n",
      "m=63\n",
      "m=64\n",
      "m=65\n",
      "m=66\n",
      "m=67\n",
      "m=68\n",
      "m=69\n",
      "m=70\n",
      "m=71\n",
      "m=72\n",
      "m=73\n",
      "m=74\n",
      "m=75\n",
      "m=76\n",
      "m=77\n",
      "m=78\n",
      "m=79\n",
      "m=80\n",
      "m=81\n",
      "m=82\n",
      "m=83\n",
      "m=84\n",
      "m=85\n",
      "m=86\n",
      "m=87\n",
      "m=88\n",
      "m=89\n",
      "m=90\n",
      "m=91\n",
      "m=92\n",
      "m=93\n",
      "m=94\n",
      "m=95\n",
      "m=96\n",
      "m=97\n",
      "m=98\n",
      "m=99\n",
      "m=100\n",
      "m=101\n",
      "m=102\n",
      "m=103\n",
      "m=104\n",
      "m=105\n",
      "m=106\n",
      "m=107\n",
      "m=108\n",
      "m=109\n",
      "m=110\n",
      "m=111\n",
      "m=112\n",
      "m=113\n",
      "m=114\n",
      "m=115\n",
      "m=116\n",
      "m=117\n",
      "m=118\n",
      "m=119\n",
      "m=120\n",
      "m=121\n",
      "m=122\n",
      "m=123\n",
      "m=124\n",
      "m=125\n",
      "m=126\n",
      "m=127\n",
      "m=128\n",
      "m=129\n",
      "m=130\n",
      "m=131\n",
      "m=132\n",
      "m=133\n",
      "m=134\n",
      "m=135\n",
      "m=136\n",
      "m=137\n",
      "m=138\n",
      "m=139\n",
      "m=140\n",
      "m=141\n",
      "m=142\n",
      "m=143\n"
     ]
    }
   ],
   "source": [
    "#### v1\n",
    "#ex1\n",
    "#log1 log2 log3 log4 |w1|\n",
    "#log5 log6 log7 log8 |w2|\n",
    "#log9 log10 log11 log12 |w3|\n",
    "#\n",
    "#log13 log14 log15 log16 |w1|\n",
    "#log17 log18 log19 log20 |w2|\n",
    "#log21 log22 log23 log24 |w3|\n",
    "#\n",
    "#log25 log26 log27 log28 |w1|\n",
    "#log29 log30 log31 log32 |w2|\n",
    "#log33 log34 log35 log36 |w3|\n",
    "#\n",
    "#log37 log38 log39 log40 |w1|\n",
    "#log41 log42 log43 log44 |w2|5534\n",
    "#log45 log46 log47 log48 |w3|\n",
    "\n",
    "logs_per_experiment = 36\n",
    "path_to_logs = \"/home/anastasiia/final_ex/final_copy/middleware1_logs/\"\n",
    "\n",
    "value_sizes = [64, 256, 512, 1024]\n",
    "client_numbers = [4, 8, 16, 32]\n",
    "workers = [8, 32, 64]\n",
    "repetitions = 3\n",
    "memtier_instances = 3\n",
    "nServers = 3\n",
    "experiments = len(workers) * len(value_sizes) * len(client_numbers) * repetitions\n",
    "\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "\n",
    "data=[]\n",
    "k = 108\n",
    "l = 0\n",
    "for v in value_sizes:\n",
    "    print(\"k=\"+str(k))\n",
    "    for w in workers:\n",
    "        for client in client_numbers:\n",
    "            for rep in range(repetitions):\n",
    "                data.append(pd.read_csv(path_to_logs+\"log_\"+str(k)+\".log\", header=None, delimiter=' '))\n",
    "                for j in range(w):\n",
    "                    d = data[l].index[data[l][0] == j].tolist()\n",
    "                    data[l] = data[l].drop([d[0]])\n",
    "                    data[l] = data[l].drop([d[len(d)-1]])\n",
    "                k += 1\n",
    "                l += 1\n",
    "    k += logs_per_experiment * 3\n",
    "        \n",
    "global_data_10 = pd.DataFrame(columns=['Middleware','Worker threads',\n",
    "                                    'Value size',\n",
    "                                    'Client number',\n",
    "                                    'Repetition',\n",
    "                                    'Worker thread',\n",
    "                                    'Time1',\n",
    "                                    'Time2',\n",
    "                                    'Time3',\n",
    "                                    'Time4',\n",
    "                                    'Time5',\n",
    "                                    'Queue size',\n",
    "                                    'Left queue',\n",
    "                                    'Successful',\n",
    "                                    'Per server1',\n",
    "                                    'Per server2',\n",
    "                                    'Per server3',\n",
    "                                    'Duration'])\n",
    "\n",
    "print(\"Start adding data to global table\")\n",
    "k = 0\n",
    "m = 0\n",
    "for value_size in value_sizes:\n",
    "    for w in workers:\n",
    "        for n in client_numbers:\n",
    "            for rep in range(repetitions):\n",
    "                print(\"m=\"+str(m))\n",
    "                for d in range (len(data[m])):\n",
    "                    if nServers == 1:\n",
    "                        newline = [1, w, value_size, n, rep, \n",
    "                             data[m].iloc[d, 0], \n",
    "                             data[m].iloc[d, 1],\n",
    "                             data[m].iloc[d, 2], \n",
    "                             data[m].iloc[d, 3], \n",
    "                             data[m].iloc[d, 4], \n",
    "                             data[m].iloc[d, 5],\n",
    "                             data[m].iloc[d, 6],\n",
    "                             data[m].iloc[d, 7], \n",
    "                             data[m].iloc[d, 8],\n",
    "                             data[m].iloc[d, 9], 0, 0, 5000]\n",
    "                    elif nServers == 3:\n",
    "                        newline = [1, w, value_size, n, rep, \n",
    "                             data[m].iloc[d, 0], \n",
    "                             data[m].iloc[d, 1],\n",
    "                             data[m].iloc[d, 2], \n",
    "                             data[m].iloc[d, 3], \n",
    "                             data[m].iloc[d, 4], \n",
    "                             data[m].iloc[d, 5],\n",
    "                             data[m].iloc[d, 6],\n",
    "                             data[m].iloc[d, 7], \n",
    "                             data[m].iloc[d, 8], \n",
    "                             data[m].iloc[d, 9], \n",
    "                             data[m].iloc[d, 10],\n",
    "                             data[m].iloc[d, 11], 5000]\n",
    "                    global_data_10.loc[k] = newline\n",
    "                    k += 1\n",
    "                m += 1    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "k1 = k # we continue to add to the table\n",
    "path_to_logs = \"/home/anastasiia/final_ex/final_copy/middleware2_logs/\"\n",
    "\n",
    "data=[]\n",
    "k = 36\n",
    "l = 0\n",
    "for v in value_sizes:\n",
    "    for w in workers:\n",
    "        for client in client_numbers:\n",
    "            for rep in range(repetitions):\n",
    "                data.append(pd.read_csv(path_to_logs+\"log_\"+str(k)+\".log\", header=None, delimiter=' '))\n",
    "                for j in range(w):\n",
    "                    d = data[l].index[data[l][0] == j].tolist()\n",
    "                    data[l] = data[l].drop([d[0]])\n",
    "                    data[l] = data[l].drop([d[len(d)-1]])\n",
    "                k += 1\n",
    "                l += 1\n",
    "    k += logs_per_experiment\n",
    "\n",
    "    \n",
    "m = 0\n",
    "for value_size in value_sizes:\n",
    "    for w in workers:\n",
    "        for n in client_numbers:\n",
    "            for rep in range(repetitions):\n",
    "                print(m)\n",
    "                for d in range (len(data[m])):\n",
    "                    if nServers == 1:\n",
    "                        newline = [2, w, value_size, n, rep, \n",
    "                             data[m].iloc[d, 0], \n",
    "                             data[m].iloc[d, 1],\n",
    "                             data[m].iloc[d, 2], \n",
    "                             data[m].iloc[d, 3], \n",
    "                             data[m].iloc[d, 4], \n",
    "                             data[m].iloc[d, 5],\n",
    "                             data[m].iloc[d, 6],\n",
    "                             data[m].iloc[d, 7], \n",
    "                             data[m].iloc[d, 8],\n",
    "                             data[m].iloc[d, 9], 0, 0, 5000]\n",
    "                    elif nServers == 3:\n",
    "                        newline = [2, w, value_size, n, rep, \n",
    "                             data[m].iloc[d, 0], \n",
    "                             data[m].iloc[d, 1],\n",
    "                             data[m].iloc[d, 2], \n",
    "                             data[m].iloc[d, 3], \n",
    "                             data[m].iloc[d, 4], \n",
    "                             data[m].iloc[d, 5],\n",
    "                             data[m].iloc[d, 6],\n",
    "                             data[m].iloc[d, 7], \n",
    "                             data[m].iloc[d, 8], \n",
    "                             data[m].iloc[d, 9], \n",
    "                             data[m].iloc[d, 10],\n",
    "                             data[m].iloc[d, 11], 5000]\n",
    "                    global_data_10.loc[k1] = newline\n",
    "                    k1 += 1\n",
    "                m += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data_10.to_pickle(\"/home/anastasiia/final_ex/final_copy/global_data_10.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_data_10 = pd.read_pickle(\"/home/anastasiia/final_ex/final_copy/global_data_10.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start drawing graphs\n"
     ]
    }
   ],
   "source": [
    "print(\"Start drawing graphs\")\n",
    "prefix=\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid_mid_cl_\"\n",
    "'''TR1_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid1_TR_value_file.txt\", \"w\")\n",
    "WTR1_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid1_WTR_value_file.txt\", \"w\")\n",
    "RT1_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid1_RT_value_file.txt\", \"w\")\n",
    "QT1_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid1_QT_value_file.txt\", \"w\")\n",
    "QS1_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid1_QS_value_file.txt\", \"w\")\n",
    "ST1_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid1_ST_value_file.txt\", \"w\")\n",
    "PT1_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid1_PT_value_file.txt\", \"w\")\n",
    "\n",
    "TR2_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid2_TR_value_file.txt\", \"w\")\n",
    "WTR2_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid2_WTR_value_file.txt\", \"w\")\n",
    "RT2_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid2_RT_value_file.txt\", \"w\")\n",
    "QT2_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid2_QT_value_file.txt\", \"w\")\n",
    "QS2_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid2_QS_value_file.txt\", \"w\")\n",
    "ST2_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid2_ST_value_file.txt\", \"w\")\n",
    "PT2_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid2_PT_value_file.txt\", \"w\")\n",
    "\n",
    "TR_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid_TR_value_file.txt\", \"w\")\n",
    "WTR_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid_WTR_value_file.txt\", \"w\")\n",
    "RT_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid_RT_value_file.txt\", \"w\")\n",
    "QT_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid_QT_value_file.txt\", \"w\")\n",
    "QS_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid_QS_value_file.txt\", \"w\")\n",
    "ST_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid_ST_value_file.txt\", \"w\")\n",
    "PT_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid_PT_value_file.txt\", \"w\")\n",
    "'''\n",
    "\n",
    "X_axis = [i * 6 for i in client_numbers]\n",
    "for w in workers:\n",
    "    TR_overall = []\n",
    "    RT_overall = []\n",
    "    QT_overall = []\n",
    "    ST_overall = []\n",
    "    QS_overall = []\n",
    "    PT_overall = []\n",
    "    \n",
    "    TR_error_overall = []\n",
    "    RT_error_overall = []\n",
    "    for value_size in value_sizes:\n",
    "        TR = []\n",
    "        RT = []\n",
    "        QT = []\n",
    "        ST = []\n",
    "        QS = []\n",
    "        PT = []\n",
    "        TR_error = []\n",
    "        RT_error = []\n",
    "        for client_number in client_numbers:\n",
    "            subset = global_data_10[(global_data_10['Worker threads'] == w) &\n",
    "                                 (global_data_10['Value size'] == value_size) & \n",
    "                                 (global_data_10['Client number'] == client_number)]\n",
    "            \n",
    "            # for graphs\n",
    "            groupped0 = subset.groupby(['Repetition']).sum()\n",
    "            groupped1 = groupped0[[ 'Time5', 'Successful']].mean()\n",
    "            RT.append(groupped1['Time5'] / groupped1['Successful'] / 1000000.0)\n",
    "            groupped_std = groupped0['Time5'] / groupped0['Successful'] / 1000000.0\n",
    "            RT_std = np.std(groupped_std.values)\n",
    "            RT_error.append(RT_std)\n",
    "            \n",
    "            groupped2 = subset.groupby(['Middleware', 'Repetition', 'Worker thread']).sum()[['Successful', 'Duration']]\n",
    "            groupped3 = groupped2['Successful'] / groupped2['Duration'] * 1000.0\n",
    "            #TR.append(groupped3.groupby(['Middleware','Repetition']).sum().groupby(['Middleware']).mean().sum())\n",
    "            TR.append(groupped3.groupby(['Middleware','Repetition']).sum().groupby(['Repetition']).sum().mean())\n",
    "            TR_std = np.std(groupped3.groupby(['Middleware','Repetition']).sum().groupby(['Repetition']).sum().values)\n",
    "            TR_error.append(TR_std)\n",
    "            \n",
    "            # for formula checks\n",
    "            # queue average time for all threads\n",
    "            groupped4 = subset.groupby(['Repetition']).sum()\n",
    "            groupped5 = groupped4[[ 'Time1', 'Successful']].mean()\n",
    "            QT.append(groupped5['Time1'] / groupped5['Successful'] / 1000000.0)\n",
    "            \n",
    "            # average service time\n",
    "            groupped6 = subset.groupby(['Repetition']).sum()\n",
    "            groupped7 = groupped6[['Time3', 'Successful']].mean()\n",
    "            ST.append(groupped7['Time3'] / groupped7['Successful'] / 1000000.0)\n",
    "            \n",
    "            # average process time\n",
    "            groupped13 = subset.groupby(['Repetition']).sum()\n",
    "            groupped14 = groupped13[['Time4', 'Successful']].mean()\n",
    "            PT.append(groupped14['Time4'] / groupped14['Successful'] / 1000000.0)\n",
    "            \n",
    "            # average queue size\n",
    "            groupped8 = subset.groupby(['Repetition']).sum()\n",
    "            groupped9 = groupped8[['Queue size', 'Successful']].mean()\n",
    "            QS.append(groupped9['Queue size'] / groupped9['Successful'])\n",
    "            \n",
    "            # TR per worker\n",
    "            #groupped10 = subset.groupby(['Repetition', 'Worker thread']).sum()[['Successful', 'Duration']]\n",
    "            #groupped11 = groupped10['Successful'] / groupped10['Duration'] * 1000.0    \n",
    "            #groupped12 = groupped11.groupby(['Repetition']).mean().mean()\n",
    "            #print(groupped12)\n",
    "        TR_overall.append(TR)\n",
    "        RT_overall.append(RT)\n",
    "        QT_overall.append(QT)\n",
    "        ST_overall.append(ST)\n",
    "        QS_overall.append(QS)\n",
    "        PT_overall.append(PT)\n",
    "        \n",
    "        TR_error_overall.append(TR_error)\n",
    "        RT_error_overall.append(RT_error)\n",
    "        \n",
    "    from matplotlib.ticker import FuncFormatter\n",
    "    def kilo(x, pos):\n",
    "        return '%1.fK' % (x*1e-3)\n",
    "    formatter = FuncFormatter(kilo)\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.axes().yaxis.set_major_formatter(formatter)\n",
    "    plt.title(\"Throughput, 2 middlewares, 3 servers configuration, # of worker threads = \"+str(w))\n",
    "    max1 = 0\n",
    "    for i in range(len(TR_overall)):\n",
    "        plt.errorbar(X_axis, TR_overall[i],\n",
    "                yerr=TR_error_overall[i],\n",
    "                fmt='-o',\n",
    "                label=\"Value size \"+str(value_sizes[i]))\n",
    "        max2 = max(TR_overall[i]) + max(TR_overall[i])/3\n",
    "        if max2 > max1:\n",
    "            max1 = max2\n",
    "    plt.ylim(0, max1)\n",
    "    plt.xlim(0, max(X_axis) + 30)\n",
    "    plt.xticks(np.arange(0, max(X_axis) + 30, 25))\n",
    "    plt.yticks(np.arange(0, max1, 2000))\n",
    "    plt.ylabel('Throughput, ops/sec')\n",
    "    plt.xlabel('Number of clients')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.tight_layout(0)\n",
    "    plt.savefig(prefix + str(w) + \"_tr.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    max1 = 0\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.title(\"Response time, 2 middlewares, 3 servers, # of worker threads = \"+str(w))\n",
    "    for i in range(len(RT_overall)):\n",
    "        plt.errorbar(X_axis, RT_overall[i],\n",
    "                yerr=RT_error_overall[i],\n",
    "                fmt='-o',\n",
    "                label=\"Value size \"+str(value_sizes[i]))\n",
    "        max2 = max(RT_overall[i]) + max(RT_overall[i])/3\n",
    "        if max2 > max1:\n",
    "            max1 = max2\n",
    "    plt.ylim(0, max1)\n",
    "    plt.ylim(0, max1)\n",
    "    plt.xlim(0, max(X_axis) + 30)\n",
    "    plt.xticks(np.arange(0, max(X_axis) + 30, 25))\n",
    "    plt.yticks(np.arange(0, max1, 1))\n",
    "    plt.ylabel('Response time, ms')\n",
    "    plt.xlabel('Number of clients') \n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.tight_layout(0)\n",
    "    plt.savefig(prefix + str(w) + \"_rt.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    max1 = 0\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.title(\"Throughput VS Response time with 2 middlewares and 3 servers configuration, # of worker threads = \"+str(w))\n",
    "    for i in range(len(RT_overall)):\n",
    "        plt.plot(TR_overall[i], RT_overall[i], '-o',\n",
    "                label=\"Value size \"+str(value_sizes[i]))\n",
    "        max2 = max(RT_overall[i]) + max(RT_overall[i])/3\n",
    "        if max2 > max1:\n",
    "            max1 = max2\n",
    "    plt.ylim(0, max1)\n",
    "    plt.ylabel('Response time, ms')\n",
    "    plt.xlabel('Throughput, ops/sec') \n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    \n",
    "    max1 = 0\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.title(\"Queue time, 1 middleware, 3 servers, # of worker threads = \"+str(w))\n",
    "    for i in range(len(QT_overall)):\n",
    "        plt.plot(X_axis, QT_overall[i], '-o',\n",
    "                label=\"Value size \"+str(value_sizes[i]))\n",
    "        max2 = max(QT_overall[i]) + max(QT_overall[i])/3\n",
    "        if max2 > max1:\n",
    "            max1 = max2\n",
    "    plt.ylim(0, max1) \n",
    "    plt.yticks(np.arange(0, max1 + 3, 1))\n",
    "    plt.xlim(0, max(X_axis) + 30)\n",
    "    plt.xticks(np.arange(0, max(X_axis) + 30, 25))\n",
    "    plt.ylabel('Queue time, ms')\n",
    "    plt.xlabel('Number of clients') \n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    print(QT_overall)\n",
    "    \n",
    "    max1 = 0\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.title(\"Service time, 1 middleware, 3 servers, # of worker threads = \"+str(w))\n",
    "    for i in range(len(ST_overall)):\n",
    "        plt.plot(X_axis, ST_overall[i], '-o',\n",
    "                label=\"Value size \"+str(value_sizes[i]))\n",
    "        max2 = max(ST_overall[i]) + max(ST_overall[i])/3\n",
    "        if max2 > max1:\n",
    "            max1 = max2\n",
    "    plt.ylim(0, max1) \n",
    "    plt.yticks(np.arange(0, max1 + 2, 0.2))\n",
    "    plt.xlim(0, max(X_axis) + 30)\n",
    "    plt.xticks(np.arange(0, max(X_axis) + 30, 25))\n",
    "    plt.ylabel('Service time, ms')\n",
    "    plt.xlabel('Number of clients') \n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    print(ST_overall)\n",
    "    \n",
    "    max1 = 0\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.title(\"Process time, 1 middleware, 3 servers, # of worker threads = \"+str(w))\n",
    "    for i in range(len(PT_overall)):\n",
    "        plt.plot(X_axis, PT_overall[i], '-o',\n",
    "                label=\"Value size \"+str(value_sizes[i]))\n",
    "        max2 = max(PT_overall[i]) + max(PT_overall[i])/3\n",
    "        if max2 > max1:\n",
    "            max1 = max2\n",
    "    plt.ylim(0, max1) \n",
    "    plt.yticks(np.arange(0, max1 + 2, 0.2))\n",
    "    plt.xlim(0, max(X_axis) + 30)\n",
    "    plt.xticks(np.arange(0, max(X_axis) + 30, 25))\n",
    "    plt.ylabel('Process time, ms')\n",
    "    plt.xlabel('Number of clients') \n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    print(PT_overall)\n",
    "    \n",
    "    \n",
    "    max1 = 0\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.title(\"Queue size, 1 middleware, 3 servers, # of worker threads = \"+str(w))\n",
    "    for i in range(len(QS_overall)):\n",
    "        plt.plot(X_axis, QS_overall[i], '-o',\n",
    "                label=\"Value size \"+str(value_sizes[i]))\n",
    "        max2 = max(QS_overall[i]) + max(QS_overall[i])/3\n",
    "        if max2 > max1:\n",
    "            max1 = max2\n",
    "    plt.ylim(0, max1) \n",
    "    plt.yticks(np.arange(0, max1 + 2, 10))\n",
    "    plt.xlim(0, max(X_axis) + 30)\n",
    "    plt.xticks(np.arange(0, max(X_axis) + 30, 25))\n",
    "    plt.ylabel('Queue size, ms')\n",
    "    plt.xlabel('Number of clients') \n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.tight_layout(0)\n",
    "    plt.savefig(prefix + str(w) + \"_qs.pdf\")\n",
    "    plt.show()\n",
    "    print(QS_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start drawing graphs\")\n",
    "prefix=\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid_mid_vl_\"\n",
    "X_axis = value_sizes\n",
    "for w in workers:\n",
    "    TR_overall = []\n",
    "    RT_overall = []\n",
    "    QT_overall = []\n",
    "    ST_overall = []\n",
    "    QS_overall = []\n",
    "    PT_overall = []\n",
    "    for client_number in client_numbers:\n",
    "        TR = []\n",
    "        RT = []\n",
    "        QT = []\n",
    "        ST = []\n",
    "        QS = []\n",
    "        PT = []\n",
    "        TR_error = []\n",
    "        RT_error = []\n",
    "        for value_size in value_sizes:\n",
    "            subset = global_data_10[(global_data_10['Worker threads'] == w) &\n",
    "                                 (global_data_10['Value size'] == value_size) & \n",
    "                                 (global_data_10['Client number'] == client_number)]\n",
    "            \n",
    "            # for graphs\n",
    "            groupped0 = subset.groupby(['Repetition']).sum()\n",
    "            groupped1 = groupped0[[ 'Time5', 'Successful']].mean()\n",
    "            RT.append(groupped1['Time5'] / groupped1['Successful'] / 1000000.0)\n",
    "            groupped_std = groupped0['Time5'] / groupped0['Successful'] / 1000000.0\n",
    "            RT_std = np.std(groupped_std.values)\n",
    "            RT_error.append(RT_std)\n",
    "            \n",
    "            groupped2 = subset.groupby(['Middleware', 'Repetition', 'Worker thread']).sum()[['Successful', 'Duration']]\n",
    "            groupped3 = groupped2['Successful'] / groupped2['Duration'] * 1000.0\n",
    "            #TR.append(groupped3.groupby(['Middleware','Repetition']).sum().groupby(['Middleware']).mean().sum())\n",
    "            TR.append(groupped3.groupby(['Middleware','Repetition']).sum().groupby(['Repetition']).sum().mean())\n",
    "            TR_std = np.std(groupped3.groupby(['Middleware','Repetition']).sum().groupby(['Repetition']).sum().values)\n",
    "            TR_error.append(TR_std)\n",
    "            \n",
    "            # for formula checks\n",
    "            # queue average time for all threads\n",
    "            groupped4 = subset.groupby(['Repetition']).sum()\n",
    "            groupped5 = groupped4[[ 'Time1', 'Successful']].mean()\n",
    "            QT.append(groupped5['Time1'] / groupped5['Successful'] / 1000000.0)\n",
    "            \n",
    "            # average service time\n",
    "            groupped6 = subset.groupby(['Repetition']).sum()\n",
    "            groupped7 = groupped6[['Time3', 'Successful']].mean()\n",
    "            ST.append(groupped7['Time3'] / groupped7['Successful'] / 1000000.0)\n",
    "            \n",
    "            # average process time\n",
    "            groupped13 = subset.groupby(['Repetition']).sum()\n",
    "            groupped14 = groupped13[['Time4', 'Successful']].mean()\n",
    "            PT.append(groupped14['Time4'] / groupped14['Successful'] / 1000000.0)\n",
    "            \n",
    "            # average queue size\n",
    "            groupped8 = subset.groupby(['Repetition']).sum()\n",
    "            groupped9 = groupped8[['Queue size', 'Successful']].mean()\n",
    "            QS.append(groupped9['Queue size'] / groupped9['Successful'])\n",
    "            \n",
    "            # TR per worker\n",
    "            #groupped10 = subset.groupby(['Repetition', 'Worker thread']).sum()[['Successful', 'Duration']]\n",
    "            #groupped11 = groupped10['Successful'] / groupped10['Duration'] * 1000.0    \n",
    "            #groupped12 = groupped11.groupby(['Repetition']).mean().mean()\n",
    "            #print(groupped12)\n",
    "        TR_overall.append(TR)\n",
    "        RT_overall.append(RT)\n",
    "        QT_overall.append(QT)\n",
    "        ST_overall.append(ST)\n",
    "        QS_overall.append(QS)\n",
    "        PT_overall.append(PT)\n",
    "        \n",
    "        TR_error_overall.append(TR_error)\n",
    "        RT_error_overall.append(RT_error)\n",
    "        \n",
    "    from matplotlib.ticker import FuncFormatter\n",
    "    def kilo(x, pos):\n",
    "        return '%1.fK' % (x*1e-3)\n",
    "    formatter = FuncFormatter(kilo)\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.axes().yaxis.set_major_formatter(formatter)\n",
    "    plt.title(\"Throughput, 2 middlewares, 3 servers, # of worker threads = \"+str(w))\n",
    "    max1 = 0\n",
    "    for i in range(len(TR_overall)):\n",
    "        plt.errorbar(X_axis, TR_overall[i],\n",
    "                yerr=TR_error_overall[i],\n",
    "                fmt='-o',\n",
    "                label=\"Client number \"+str(client_numbers[i]))\n",
    "        max2 = max(TR_overall[i]) + max(TR_overall[i])/3\n",
    "        if max2 > max1:\n",
    "            max1 = max2\n",
    "    plt.ylim(0, max1)\n",
    "    plt.xlim(0, max(X_axis) + 100)\n",
    "    plt.xticks(np.arange(0, max(X_axis) + 100, 100))\n",
    "    plt.yticks(np.arange(0, max1, 2000))\n",
    "    plt.ylabel('Throughput, ops/sec')\n",
    "    plt.xlabel('Value size, Bytes')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.tight_layout(0)\n",
    "    plt.savefig(prefix + str(w) + \"_tr.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    max1 = 0\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.title(\"Response time, 2 middlewares, 3 servers, # of worker threads = \"+str(w))\n",
    "    for i in range(len(RT_overall)):\n",
    "        plt.errorbar(X_axis, RT_overall[i],\n",
    "                yerr=RT_error_overall[i],\n",
    "                fmt='-o',\n",
    "                label=\"Client number \"+str(client_numbers[i]))\n",
    "        max2 = max(RT_overall[i]) + max(RT_overall[i])/3\n",
    "        if max2 > max1:\n",
    "            max1 = max2\n",
    "        plt.ylim(0, max1)\n",
    "    plt.xlim(0, max(X_axis) + 100)\n",
    "    plt.xticks(np.arange(0, max(X_axis) + 100, 100))\n",
    "    plt.yticks(np.arange(0, max1, 1))\n",
    "    plt.ylabel('Response time, ms')\n",
    "    plt.xlabel('Value size, Bytes') \n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.tight_layout(0)\n",
    "    plt.savefig(prefix + str(w) + \"_rt.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TR_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_cl_TR_value_file.txt\", \"w+\")\n",
    "RT_value_file = open(\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_cl_RT_value_file.txt\", \"w+\")\n",
    "\n",
    "\n",
    "path_to_experiment=\"/home/anastasiia/final_ex/final_copy/part6/\"\n",
    "prefix=\"/home/anastasiia/asl-project-2019-ruzhanskaia/report_src/part6_mid_cl_cl_\"\n",
    "value_sizes=[64, 256, 512, 1024]\n",
    "client_numbers=[4, 8, 16, 32]\n",
    "workers = [8, 32, 64]\n",
    "repetitions = 3\n",
    "memtier_instances = 6\n",
    "experiments = len(workers) * len(value_sizes) * len(client_numbers) * repetitions\n",
    "\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean \n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "clients_data = []\n",
    "\n",
    "for i in range(memtier_instances):\n",
    "    initial = open(path_to_experiment+\"client\"+str(i+1)+\".log\",\"r\")\n",
    "    lines = initial.readlines()\n",
    "    total_ops = 0\n",
    "    for line in lines:\n",
    "        if line.startswith(\"[RUN #1 100%\"):\n",
    "            line = re.sub(' +', ' ', line)\n",
    "            parts = line.split(' ')\n",
    "            total_ops = parts[7]\n",
    "        if line.startswith(\"Gets\"):\n",
    "            line = re.sub(' +', ' ', line)\n",
    "            parts = line.split(' ')\n",
    "            parts = [parts[1], parts[4], parts[5], total_ops]\n",
    "            clients_data.append(parts) \n",
    "    initial .close()\n",
    "\n",
    "\n",
    "global_data = pd.DataFrame(columns=['Worker threads', 'Value size', 'Client number', 'Repetition', 'Memtier instance', 'TR', 'RT', 'TR_B', 'Total ops'])\n",
    "\n",
    "j = 0\n",
    "k = 0\n",
    "for value_size in value_sizes:\n",
    "    for w in workers:\n",
    "        for n in client_numbers:\n",
    "            for rep in range(repetitions):\n",
    "                for memtier in range(memtier_instances):\n",
    "                    d = [w, value_size, n, rep, memtier, clients_data[memtier * experiments + k][0], clients_data[memtier * experiments + k][1], clients_data[memtier * experiments + k][2], clients_data[memtier * experiments + k][3]]\n",
    "                    global_data.loc[j] = d\n",
    "                    j += 1\n",
    "                k += 1\n",
    "\n",
    "global_data['Worker threads'] = global_data['Worker threads'].astype(int)\n",
    "global_data['Value size'] = global_data['Value size'].astype(int)\n",
    "global_data['Client number'] = global_data['Client number'].astype(int)\n",
    "global_data['Repetition'] = global_data['Repetition'].astype(int)\n",
    "global_data['Memtier instance'] = global_data['Memtier instance'].astype(int)\n",
    "global_data['TR'] = global_data['TR'].astype(float)\n",
    "global_data['RT'] = global_data['RT'].astype(float)\n",
    "global_data['TR_B'] = global_data['TR_B'].astype(float)\n",
    "global_data['Total ops'] = global_data['Total ops'].astype(int)\n",
    "\n",
    "global_data['Total time'] = global_data['RT']*global_data['Total ops']\n",
    "\n",
    "TR_graph = []\n",
    "X_axis =[i * 6 for i in client_numbers]\n",
    "\n",
    "for w in workers:\n",
    "    TR_overall = []\n",
    "    RT_overall = []\n",
    "    TR_B_overall = []\n",
    "    TR_error_overall = []\n",
    "    RT_error_overall = []\n",
    "    for value_size in value_sizes:\n",
    "        TR = []\n",
    "        RT = []\n",
    "        TR_B = []\n",
    "        TR_error = []\n",
    "        RT_error = []\n",
    "\n",
    "        for client_number in client_numbers:\n",
    "            subset = global_data[(global_data['Worker threads'] == w) &\n",
    "                                 (global_data['Value size'] == value_size) & \n",
    "                                 (global_data['Client number'] == client_number)]\n",
    "            groupped = subset.groupby(['Repetition']).sum()\n",
    "            TR_std = np.std(groupped['TR'].values)\n",
    "            TR_error.append(TR_std)\n",
    "            TR.append(float(groupped.mean()['TR']))\n",
    "            # print to file\n",
    "            TR_value_file.write(str(w) + \" \" + str(value_size) + \" \" + str(client_number) + \n",
    "                                \" \" + str(groupped.mean()['TR']))\n",
    "            for v in groupped['TR'].values:\n",
    "                TR_value_file.write(\" \" + str(v))\n",
    "            TR_value_file.write(\"\\n\")\n",
    "            \n",
    "            # end print to file\n",
    "            \n",
    "            groupped1 = subset.groupby(['Repetition']).sum()\n",
    "            groupped2 = groupped1['Total time']/groupped1['Total ops']\n",
    "            RT.append(float(groupped2.mean()))\n",
    "            RT_std = np.std(groupped2.values)\n",
    "            RT_error.append(RT_std)\n",
    "             # print to file\n",
    "            RT_value_file.write(str(w) + \" \" + str(value_size) + \" \" + str(client_number) + \n",
    "                                \" \" + str(groupped2.mean()))\n",
    "            for v in groupped2.values:\n",
    "                RT_value_file.write(\" \" + str(v))\n",
    "            RT_value_file.write(\"\\n\")\n",
    "            # end print to file\n",
    "            \n",
    "            groupped3 = subset.groupby(['Repetition']).sum()\n",
    "            TR_B.append(float(groupped3.mean()['TR_B']))\n",
    "            \n",
    "        TR_overall.append(TR)\n",
    "        RT_overall.append(RT)\n",
    "        TR_error_overall.append(TR_error)\n",
    "        RT_error_overall.append(RT_error)\n",
    "        TR_B_overall.append(TR_B)\n",
    "\n",
    "    from matplotlib.ticker import FuncFormatter\n",
    "    def kilo(x, pos):\n",
    "        return '%1.fK' % (x*1e-3)\n",
    "    formatter = FuncFormatter(kilo)\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.axes().yaxis.set_major_formatter(formatter)\n",
    "    plt.title(\"Throughput, 2 middlewares, 3 servers configuration,  # of worker threads = \"+str(w))\n",
    "    max1 = 0\n",
    "    for i in range(len(TR_overall)):\n",
    "        plt.errorbar(X_axis, TR_overall[i],\n",
    "                yerr=TR_error_overall[i],\n",
    "                fmt='-o',\n",
    "                label=\"Value size \"+str(value_sizes[i]))\n",
    "        max2 = max(TR_overall[i]) + max(TR_overall[i])/2\n",
    "        if max2 > max1:\n",
    "            max1 = max2\n",
    "    plt.ylim(0, max1)\n",
    "    plt.xticks(np.arange(0, max(X_axis), 25))\n",
    "    plt.yticks(np.arange(0, max1, 2000))\n",
    "    plt.ylabel('Throughput, ops/sec')\n",
    "    plt.xlabel('Number of clients')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.tight_layout(0)\n",
    "    plt.savefig(prefix + str(w)+\"_tr.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.axes().yaxis.set_major_formatter(formatter)\n",
    "    plt.title(\"Throughput in KB/sec, 2 middlewares, 1 server, # of worker threads = \"+str(w))\n",
    "    max1 = 0\n",
    "    for i in range(len(TR_B_overall)):\n",
    "        plt.plot(X_axis, TR_B_overall[i],'-o',\n",
    "                label=\"Value size \"+str(value_sizes[i]))\n",
    "        max2 = max(TR_B_overall[i]) + max(TR_B_overall[i])/3\n",
    "        if max2 > max1:\n",
    "            max1 = max2\n",
    "    plt.ylim(0, max1)\n",
    "    plt.xticks(np.arange(0, max(X_axis), 25))\n",
    "    plt.yticks(np.arange(0, max1, 2000))\n",
    "    plt.ylabel('Throughput, KB/sec')\n",
    "    plt.xlabel('Number of clients')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.tight_layout(0)\n",
    "    plt.savefig(prefix + str(w)+\"_tr_b.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    max1 = 0\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.title(\"Response time, 2 middlewares, 3 servers,  # of worker threads = \"+str(w))\n",
    "    for i in range(len(RT_overall)):\n",
    "        plt.errorbar(X_axis, RT_overall[i],\n",
    "                yerr=RT_error_overall[i],\n",
    "                fmt='-o',\n",
    "                label=\"Value size \"+str(value_sizes[i]))\n",
    "        max2 = max(RT_overall[i]) + max(RT_overall[i])/2\n",
    "        if max2 > max1:\n",
    "            max1 = max2\n",
    "    plt.ylim(0, max1)\n",
    "    plt.xticks(np.arange(0, max(X_axis), 25))\n",
    "    plt.yticks(np.arange(0, max1, 2))\n",
    "    plt.ylabel('Response time, ms')\n",
    "    plt.xlabel('Number of clients') \n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.tight_layout(0)\n",
    "    plt.savefig(prefix + str(w)+\"_rt.pdf\") \n",
    "    plt.show()\n",
    "\n",
    "    max1 = 0\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title(\"Throughput vs Response time, 3 servers and 2 middlewares configuration, \"+str(w) + \" threads\")\n",
    "    for i in range(len(RT_overall)):\n",
    "        plt.errorbar(TR_overall[i], RT_overall[i],\n",
    "                xerr=TR_error_overall[i],\n",
    "                yerr=RT_error_overall[i],\n",
    "                fmt='-o',\n",
    "                label=\"Value size \"+str(value_sizes[i]))\n",
    "        max2 = max(RT_overall[i]) + max(RT_overall[i])/2\n",
    "        if max2 > max1:\n",
    "            max1 = max2\n",
    "    plt.ylim(0, max1)\n",
    "    plt.ylabel('Response time, ms')\n",
    "    plt.xlabel('Throughput, ops/sec') \n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "TR_value_file.close()\n",
    "RT_value_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
